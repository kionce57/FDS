# 技術重構藍圖：AI 之眼 (長照監控系統)

**Technical Refactoring Blueprint: AI Eye Fall Detection System**

## 文件屬性

| 項目     | 內容                                                         |
| -------- | ------------------------------------------------------------ |
| 審查者   | Linus AI (Technical Consultant)                              |
| 優先級   | P0 (Critical) - 架構重寫                                     |
| 目標     | 解決 OOM (記憶體溢出)、GIL 阻塞、以及高誤報率問題            |
| 適用硬體 | Edge Devices (Jetson Nano/Orin, Raspberry Pi 5, x86 Mini PC) |

---

## 0. 執行摘要 (Executive Summary)

目前的「雙管線 + BBox 長寬比 + Raw Frame Buffer」架構在物理上不可行。若直接部署，系統將面臨以下必然結果：

- **崩潰 (Crash)**: 20秒的 Raw Frame 緩衝區將耗盡邊緣裝置 RAM。
- **凍結 (Freeze)**: Python GIL 與 I/O 阻塞將導致跌倒發生時系統無回應。
- **誤報 (False Positives)**: 二維 BBox 無法區分「彎腰」、「躺臥」與「跌倒」。

本文件定義了**強制性 (Mandatory)** 的重構路徑，以確保系統具備生產級 (Production-grade) 的強健性。

---

## 1. 核心演算法重構 (Algorithm)

### 🔴 當前問題 (Current Issue)

依賴 **BBox 長寬比變化** 作為跌倒特徵。

- **原因**: 這是二維幾何方案，缺乏三維語義。老人彎腰、蹲下、或攝像頭角度改變都會觸發誤報。
- **判定**: Garbage Design (垃圾設計)。

### 🟢 重構指令 (Refactoring Mandate)

廢棄長寬比邏輯，全面啟用 **Pose Estimation (骨架分析)**。

**實作細節：**

1. **模型切換**: 使用 `yolo11n-pose.pt` (或更高版本)。
2. **邏輯定義**:
   - **向量計算**: 建立「脊椎向量」(頸部 Keypoint 到 骨盆 Keypoint)。
   - **夾角閾值**: 計算脊椎向量與地平線 (Y軸) 的夾角。
     - `Angle < 30 deg` (接近水平) → 高度懷疑跌倒。
   - **速度檢測**: Head Keypoint 的 Y 軸下降速度超過閾值。

> **優勢**: 即使老人蜷縮在地上（BBox 長寬比可能正常），骨架倒伏特徵依然能精確觸發。

---

## 2. 系統架構與併發模型 (Concurrency & Pipeline)

### 🔴 當前問題 (Current Issue)

依賴 Python `threading` 模組試圖分離 Capture 與 Analysis，且使用 OpenCV 預設 CPU 編碼。

- **原因**: Python GIL (全域解譯器鎖) 導致多線程無法利用多核 CPU。`cv2.read()` 與 `np.copy()` 造成巨大的記憶體頻寬爭奪。
- **判定**: Implementation Hell (實作地獄)。

### 🟢 重構指令 (Refactoring Mandate)

實施「**控制與資料分離**」。Python 僅負責邏輯控制，資料流動 (IO) 必須留在 C/C++ 層或硬體層。

**方案選擇 (依團隊能力三選一)：**

| 方案             | 難度       | 適用場景           | 關鍵技術關鍵字                                 |
| ---------------- | ---------- | ------------------ | ---------------------------------------------- |
| **Plan A: 入門** | ⭐⭐       | 快速驗證 / x86 PC  | Ultralytics `stream=True`, subprocess (FFmpeg) |
| **Plan B: 標準** | ⭐⭐⭐⭐   | 標準 Linux 開發    | GStreamer, PyGObject, Queue                    |
| **Plan C: 專家** | ⭐⭐⭐⭐⭐ | NVIDIA Jetson 系列 | DeepStream, TensorRT, NvDsBatchMeta            |

### 實作細節 (Plan A 為例)

> [!CAUTION]
> 嚴禁使用 `while True: frame = cv2.read()`。

必須使用 Iterator 模式交出 I/O 控制權：

```python
# 讓底層 C++ 處理讀取與預處理
results = model.predict(source="rtsp://...", stream=True)

for result in results:
    # 僅在此處處理 AI 結果 (Metadata)
    # 不要在此處做任何 heavy I/O
    process_keypoints(result.keypoints)
```

---

## 3. 記憶體管理與緩衝區 (Memory & Buffering)

### 🔴 當前問題 (Current Issue)

Rolling Buffer 儲存 `np.ndarray` (Raw Frames)。

- **算術證明**: `1080p RGB @ 30fps x 20s ≈ 3.73 GB RAM`
- **後果**: 邊緣裝置 OOM 當機；寫入 SD 卡時 I/O Blocking 導致系統凍結。
- **判定**: Arithmetic Failure (算術不及格)。

### 🟢 重構指令 (Refactoring Mandate)

實施「**先壓縮，後緩衝 (Compress-First Buffering)**」。

**實作細節：**

1. **硬體編碼 (Hardware Encoding)**:
   - 影像輸入後，第一步是送入硬體編碼器 (NVENC, VideoCore, QuickSync)。
   - 將影像轉為 H.264 NAL Units (封包)。

2. **緩衝封包 (Buffer Packets)**:
   - Rolling Buffer 僅儲存 H.264 封包。
   - 記憶體預估: `20秒影片 ≈ 5MB - 10MB`。
   - **效益**: RAM 佔用降低 300 倍。

3. **零延遲存檔 (Zero-Latency Save)**:
   - 當 AI 觸發 `CONFIRMED` 狀態，直接將記憶體中的 5MB 封包寫入磁碟。
   - 此操作耗時 `< 100ms`，不會造成系統卡頓。

---

## 4. 開發檢查清單 (Developer Checklist)

請開發同仁在提交程式碼前，確認以下項目皆已打勾：

- [ ] **No Raw Buffer**: 確認沒有任何全域 List 正在儲存 `numpy.ndarray` 格式的影像序列。
- [ ] **Hardware Ops**: 確認影像編碼使用了硬體加速 (如 `h264_nvenc`, `omxh264enc`)，而非 OpenCV 預設的 CPU 編碼。
- [ ] **Zero Copy** _(Optional but Recommended)_: 確認影像從 Capture 到 Inference 的過程中，沒有發生 `deepcopy()`。
- [ ] **Pose Logic**: 確認跌倒判定邏輯是基於 Keypoint 向量夾角，而非 BBox 形狀。
- [ ] **I-Frame Awareness**: 確保儲存影片時，是從最近的一個 I-Frame (關鍵幀) 開始切分，避免影片開頭花屏。

---

> [!NOTE]
> **Linus' Note:**
>
> _"Efficiency is not just about speed, it's about not doing unnecessary work."_
>
> 不要讓 CPU 搬運像素，那是 GPU 和 DMA 的工作。Python 的工作是指揮，不是做苦力。
