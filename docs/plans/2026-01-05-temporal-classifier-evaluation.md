# Temporal Classifier 技術選型評估

> **目標**：在現有 YOLO Pose 偵測基礎上，引入時序分類器處理滑動視窗特徵，降低跌倒偵測的誤報率（False Positive Rate）。

---

## 現狀分析

**Current Pipeline:**

```
Camera → YOLO Pose → Skeleton → PoseRuleEngine (軀幹角度 > 60°) → DelayConfirm (3s FSM)
```

**誤報原因：**

- 單幀判斷無法區分「快速坐下」vs「跌倒」
- 軀幹角度閾值對邊界情況敏感
- 關鍵點抖動導致瞬時誤判

**解決方向：** 引入時序分類器，分析 N 幀滑動視窗內的運動模式

---

## 技術方案比較

### 方案一覽表

| 方案          | 模型類型    | 輸入特徵      | 優勢               | 風險           | 推薦指數   |
| ------------- | ----------- | ------------- | ------------------ | -------------- | ---------- |
| ❶ LSTM/GRU    | RNN         | Skeleton 序列 | 成熟穩定、文獻豐富 | 長序列梯度問題 | ⭐⭐⭐⭐   |
| ❷ TCN         | CNN         | Skeleton 序列 | 並行運算、邊緣友好 | 感受野需調校   | ⭐⭐⭐⭐⭐ |
| ❸ Transformer | Attention   | Skeleton 序列 | 長距離依賴         | 計算量大       | ⭐⭐⭐     |
| ❹ GCN-LSTM    | Graph+RNN   | 骨架圖        | 關節空間關係       | 複雜度高       | ⭐⭐⭐     |
| ❺ 輕量 MLP    | Feedforward | 統計特徵      | 極簡快速           | 表達力有限     | ⭐⭐⭐⭐   |
| ❻ 增強規則    | 狀態機      | 衍生特徵      | 無需訓練、可解釋   | 難以泛化       | ⭐⭐⭐     |

---

## 詳細方案分析

### ❶ LSTM / GRU（推薦）

**架構：**

```
Skeleton(17×3) → Flatten(51D) → LSTM(64 hidden) → Dense(2) → fall/not_fall
```

**滑動視窗：** 30 幀 (2 秒 @ 15fps)

| 指標       | 評估                                              |
| ---------- | ------------------------------------------------- |
| 準確率提升 | 研究顯示可將 FPR 降低 11-50%                      |
| 邊緣部署   | ONNX 量化後可跑 Raspberry Pi 4（~50ms/inference） |
| 訓練成本   | 中等（需 500+ 跌倒樣本）                          |
| 實作複雜度 | 中等                                              |

**風險：** 需要收集/標註跌倒數據集

---

### ❷ TCN - Temporal Convolutional Network（強烈推薦）

**架構：**

```
Skeleton(30×51) → 1D Conv(dilated) → 1D Conv(dilated) → GlobalPool → Dense(2)
```

| 指標       | 評估                                   |
| ---------- | -------------------------------------- |
| 準確率提升 | 與 LSTM 相當，部分研究優於 RNN         |
| 邊緣部署   | **最佳**，純卷積並行計算，邊緣裝置友好 |
| 訓練成本   | 中等                                   |
| 實作複雜度 | 低（標準 Conv1D 堆疊）                 |

**優勢：**

- 無隱藏狀態，推理速度穩定
- Dilated convolution 可覆蓋長時間範圍
- ONNX 導出簡單，量化友好

---

### ❸ Transformer (ST-TR)

**架構：**

```
Skeleton(30×17×3) → Spatial Attention → Temporal Attention → Classification
```

| 指標       | 評估                                  |
| ---------- | ------------------------------------- |
| 準確率提升 | 最高（NTU-RGB+D 基準測試領先）        |
| 邊緣部署   | **困難**，Self-Attention O(n²) 計算量 |
| 訓練成本   | 高（需大量數據 + 調參）               |
| 實作複雜度 | 高                                    |

**風險：** 邊緣裝置推理延遲可能超過 100ms，不適合實時場景

---

### ❹ GCN-LSTM 混合

**架構：**

```
Skeleton → GCN(空間建模) → LSTM(時序建模) → Classification
```

| 指標       | 評估                       |
| ---------- | -------------------------- |
| 準確率提升 | 高，可建模關節間的空間依賴 |
| 邊緣部署   | 困難，GCN 稀疏運算效率低   |
| 訓練成本   | 高                         |
| 實作複雜度 | 高（需圖結構處理）         |

---

### ❺ 輕量 MLP + 統計特徵

**架構：**

```
滑動視窗 → 手工特徵提取 → MLP → Classification
```

**特徵設計：**

- 臀部下降速度
- 軀幹角度變化率
- 關鍵點 Y 座標標準差
- 身高變化

| 指標       | 評估                     |
| ---------- | ------------------------ |
| 準確率提升 | 中等（依賴特徵工程品質） |
| 邊緣部署   | **最佳**，<5ms 推理      |
| 訓練成本   | 低                       |
| 實作複雜度 | 低                       |

**適用場景：** 快速驗證、資源極度受限環境

---

### ❻ 增強規則引擎（無 ML）

**策略：** 擴展現有 `PoseRuleEngine`

```python
def is_fallen_v2(self, skeleton_window: list[Skeleton]) -> bool:
    # 1. 臀部下降速度 > 閾值
    hip_drop_velocity = self._calc_hip_drop(skeleton_window)

    # 2. 軀幹角度持續 > 60° 超過 N 幀
    angle_sustained = all(s.torso_angle > 60 for s in skeleton_window[-10:])

    # 3. 最終姿態：臀部高度比 < 0.3
    final_hip_ratio = skeleton_window[-1].hip_height_ratio

    return hip_drop_velocity > 0.5 and angle_sustained and final_hip_ratio < 0.3
```

| 指標       | 評估                   |
| ---------- | ---------------------- |
| 準確率提升 | 有限，難以處理複雜情況 |
| 邊緣部署   | **零成本**             |
| 訓練成本   | 無                     |
| 實作複雜度 | 低                     |

---

## 技術選型決策表

| 維度           | LSTM/GRU |  TCN  | Transformer | GCN-LSTM |  MLP  | 規則增強 |
| -------------- | :------: | :---: | :---------: | :------: | :---: | :------: |
| **準確率潛力** |   ★★★★   | ★★★★  |    ★★★★★    |  ★★★★☆   |  ★★★  |   ★★☆    |
| **FPR 降低**   |   ★★★★   | ★★★★  |    ★★★★★    |   ★★★★   |  ★★★  |   ★★☆    |
| **邊緣部署**   |   ★★★☆   | ★★★★★ |     ★★      |    ★★    | ★★★★★ |  ★★★★★   |
| **推理速度**   |   ★★★☆   | ★★★★☆ |     ★★      |   ★★☆    | ★★★★★ |  ★★★★★   |
| **開發成本**   |    中    | 低-中 |     高      |    高    |  低   |   極低   |
| **資料需求**   |   500+   | 500+  |    2000+    |  1000+   | 200+  |    0     |
| **ONNX 友好**  |   ★★★★   | ★★★★★ |     ★★★     |   ★★☆    | ★★★★★ |   N/A    |

---

## 推薦實施路徑

### Phase 1：增強規則引擎（1-2 天）

- 無成本快速驗證
- 增加臀部下降速度、持續角度判斷
- 評估 FPR 改善幅度

### Phase 2：TCN 原型（1-2 週）

- 若 Phase 1 效果不足
- 實作輕量 TCN (3-4 層 dilated conv)
- 使用公開數據集 pre-training + 少量自有數據 fine-tuning

### Phase 3：LSTM 備選（如 TCN 效果不佳）

- GRU 更輕量，優先考慮
- ONNX 量化部署

---

## 待確認事項

1. **目標 FPR**：希望降低到什麼水平？（目前估計？目標值？）
2. **邊緣硬體**：Raspberry Pi 4/5 或其他？GPU 可用嗎？
3. **數據集**：是否有已標註的跌倒影片？數量？
4. **延遲容忍**：最大可接受推理延遲？（100ms? 200ms?）

---

_文件建立日期：2026-01-05_
