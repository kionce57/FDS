# å¯èƒ½çš„æ–¹å‘

## 1

```mermaid
graph TD
    %% Hardware Layer
    subgraph Hardware [Layer 0: Hardware & Input]
        CAM[Camera Source / RTSP] -->|Raw Stream| CAP[Capture Thread]
    end

    %% Memory Layer - The "Time Machine"
    subgraph Memory [Layer 1: In-Memory Ring Buffer]
        CAP -->|Push Frame| RB["Rolling Buffer\n(Keep last 150 frames)"]
        note_rb["Note: Zero-copy if possible.\nThis enables 'Pre-event' recording."]
    end

    %% Core Processing Loop - Must run at Target FPS
    subgraph Core [Layer 2: Detection Loop]
        CAP -->|Latest Frame| YOLO[YOLOv8 Inference]
        YOLO -->|BBox & Keypoints| RULE["Rule Engine\nAspect Ratio < 1.3"]

        RULE -- Normal --> STATE_RESET[Reset Counter]
        RULE -- Potential Fall --> STATE_CHECK["Delay Confirmation\n(State Machine)"]

        STATE_CHECK -- "Wait (t < 3s)" --> WAIT[Accumulate Confidence]
        STATE_CHECK -- "Confirmed (t >= 3s)" --> EVENT[Event Trigger]
    end

    %% Async Event Handling - Don't block the loop!
    subgraph Actions [Layer 3: Async Event Handlers]
        EVENT -->|1. Fire & Forget| NOTIFY[LINE Notify Service]
        EVENT -->|2. Dump Buffer + Record| REC[Clip Recorder]
        EVENT -->|3. Write Metadata| DB[(SQLite Database)]

        REC -->|Save .mp4| DISK[Local Disk /data/clips]
        DB -->|Log Event| DISK
    end

    %% Background Tasks
    subgraph Background [Layer 4: Maintenance & Sync]
        DISK -.->|Cron/Worker| SYNC["Cloud Sync Service\n(GCP Storage)"]
        DISK -.->|Cron/Worker| CLEAN["Cleanup Service\n(Delete old mp4)"]
    end

    %% Viewer
    subgraph UserSpace [User Interface]
        WEB[FastAPI Dashboard] -->|Read| DB
        WEB -->|Stream| DISK
    end

    %% Relationships
    RB -.->|Extract -10s| REC
    style RB fill:#f9f,stroke:#333,stroke-width:2px,color:black
    style EVENT fill:#f00,stroke:#333,stroke-width:4px,color:white
    style YOLO fill:#ff9,stroke:#333,stroke-width:2px,color:black
```

## 1.5

```mermaid
stateDiagram-v2
    direction LR
    [*] --> Standing

    state "Standing / Walking" as Standing {
        [*] --> CheckVertical
        CheckVertical --> Normal: Torso â€¢ Gravity > 0.8
        CheckVertical --> Leaning: Torso â€¢ Gravity < 0.8
    }

    Standing --> Unstable: Velocity_Y > Threshold (Impact)
    Standing --> Unstable: Angle < 45Â°

    state "Unstable / Falling" as Unstable {
        [*] --> Monitoring
        Monitoring --> Fallen: Stay Low for > 2s
        Monitoring --> Standing: Recovered (Got up)
    }

    state "FALL DETECTED" as Fallen {
        [*] --> TriggerAlert
        TriggerAlert --> [*]
    }
```

## 2

```mermaid
graph LR
    subgraph Edge_Compute ["Edge Device (Jetson/Pi)"]
        direction TB
        Input[("ğŸ“· Camera Source<br/>(RTSP/USB)")]

        subgraph Perception ["Perception Loop (Neural Net)"]
            YOLO["ğŸš€ YOLOv8-Pose<br/>(TensorRT Optimized)"]
        end

        subgraph Physics ["Physics Engine (The Truth)"]
            Vectors["ğŸ“ Vector Analysis<br/>(Torso Angle + Velocity)"]
            Threshold{"Fall Logic<br/>(Angle < 20Â° &<br/>High Impact)"}
        end

        Buffer[("ğŸ”„ Rolling Buffer<br/>(RAM - Last 10s)")]
    end

    subgraph Actions ["Output Vectors"]
        Line["ğŸ“± LINE Notify<br/>(Webhook)"]
        DB[("ğŸ’¾ SQLite<br/>(Event Metadata)")]
        Storage[("ğŸ“‚ Local Storage<br/>(Evidence Clip)")]
    end

    %% Flows
    Input -->|Raw Frames| YOLO
    Input -->|Raw Frames| Buffer
    YOLO -->|"Keypoints (x,y,c)"| Vectors
    Vectors --> Threshold

    Threshold -->|FALSE| Vectors
    Threshold -->|TRUE| Line
    Threshold -->|TRUE| DB

    %% Video Dump Logic
    Threshold -->|Trigger| Storage
    Buffer -.->|Dump Cached Frames| Storage

    %% Styling
    classDef hardware fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef ai fill:#f3e5f5,stroke:#4a148c,stroke-width:2px;
    classDef logic fill:#fff3e0,stroke:#e65100,stroke-width:2px;
    classDef action fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px;

    class Input,Buffer hardware;
    class YOLO ai;
    class Vectors,Threshold logic;
    class Line,DB,Storage action;
```

## 2.5

### Phase 1: Context & Reality Check

å¦‚æœä½ çœŸçš„åœ¨ç”¨ **LLM (Large Language Model)** ä¾†åˆ¤æ–·ä¸€å€‹äººæ˜¯å¦è·Œå€’ï¼Œé€™å®Œå…¨æ˜¯è³‡æºèª¤ç”¨ã€‚

- **è·Œå€’æ˜¯ä¸€å€‹ç‰©ç†äº‹ä»¶ï¼ˆPhysics Eventï¼‰**ï¼šæ˜¯é‡åŠ›ï¼ˆGravityï¼‰ï¼Œæ˜¯ $F=ma$ï¼Œæ˜¯å¹¾ä½•è®ŠåŒ–ã€‚
- **ä¸éœ€è¦ LLM**ï¼šä½ ä¸éœ€è¦ä¸€å€‹å¹¾åå„„åƒæ•¸çš„æ¨¡å‹ä¾†å‘Šè¨´ä½ ã€Œå‚ç›´çš„çŸ©å½¢è®Šæˆäº†æ°´å¹³çš„ã€ã€‚
- **çµè«–**ï¼šé€™æ˜¯å°ç®—åŠ›è³‡æºçš„çŠ¯ç½ªã€‚å¦‚æœæ˜¯ç‚ºäº†å·¥ç¨‹è½åœ°ï¼Œ**Delete it immediately**.

### Phase 2: Delete (åˆªé™¤éƒ¨åˆ†)

æœ€å¥½çš„éƒ¨åˆ†å°±æ˜¯æ²’æœ‰éƒ¨åˆ†ï¼ˆThe best part is no partï¼‰ã€‚

1. **Delete LLM Module**

   - ç”¨ç°¡å–®çš„**å¹¾ä½•æ•¸å­¸ï¼ˆGeometry Mathï¼‰**ä»£æ›¿ã€‚
   - è¨ˆç®— Bounding Box çš„ Aspect Ratio æˆ–è€… Keypoints çš„è§’åº¦å‘é‡ã€‚
   - å»¶é²ï¼ˆLatencyï¼‰å¾å¹¾ç™¾æ¯«ç§’é™åˆ°å¾®ç§’ç´šï¼ˆMicrosecondsï¼‰ã€‚

2. **Refactor OpenCV**

   - é€™æ˜¯å·¥å…·åº«ï¼Œä¸æ˜¯æ¶æ§‹æ¨¡çµ„ã€‚æŠŠå®ƒæ•´åˆé€² Detection Loopã€‚ä¸è¦è®“å®ƒæˆç‚ºä¸€å€‹å–®ç¨çš„ã€Œæ­¥é©Ÿã€ã€‚

3. **Consolidate Storage**
   - **Current State**: Local å½±åƒç·©å­˜å€ & é›²ç«¯éª¨æ¶å„²å­˜å€ & äº‹ä»¶åŸå§‹å½±åƒå„²å­˜ (ä¸‰å€‹å„²å­˜æ¡¶ï¼Ÿé€™æ˜¯æ•¸æ“šç¢ç‰‡åŒ–)ã€‚
   - **Fix**: å¦‚æœä½ æœ‰ Docker Volumeï¼Œä½ åªéœ€è¦ä¸€å€‹çµ±ä¸€çš„ Event Logã€‚
   - **GCP Strategy**: ç‚ºä»€éº¼è¦æŠŠã€Œéª¨æ¶ JSONã€å‚³åˆ° GCPï¼Ÿé™¤éè¦åšå¤§è¦æ¨¡è¨“ç·´ï¼Œå¦å‰‡é€™æ˜¯æµªè²»é »å¯¬ã€‚å»ºè­°æ‰“åŒ…æˆä¸€å€‹äº‹ä»¶æª”ï¼ˆVideo + Metadataï¼‰ä¸€æ¬¡ä¸Šå‚³ã€‚

### Phase 3: Simplify (ç°¡åŒ–æµç¨‹)

ç›®å‰çš„æµç¨‹å¤ªé•·äº†ï¼š
`Camera` $\rightarrow$ `Array` $\rightarrow$ `Detection` $\rightarrow$ `Judge (LLM??)` $\rightarrow$ `Delay` $\rightarrow$ `Notify`

**å„ªåŒ–å¾Œçš„ç‰©ç†è·¯å¾‘**ï¼š
`Sensor (Photon)` $\rightarrow$ `Compute (Tensor)` $\rightarrow$ `Action (Signal)`

**é‡æ–°è¨­è¨ˆé‚è¼¯**ï¼š

1. **Detection (YOLOv8)**: ç›´æ¥è¼¸å‡º Keypointsã€‚
2. **Logic**: ä¸è¦åªçœ‹é•·å¯¬æ¯”ï¼ˆAspect Ratioï¼‰ã€‚é•·å¯¬æ¯”æ˜¯å¼±æŒ‡æ¨™ï¼ˆWeak Signalï¼‰ã€‚ä¸€å€‹äººå½è…°ç¶é‹å¸¶ï¼Œé•·å¯¬æ¯”ä¹Ÿæœƒè®Šã€‚
3. **First Principles Fix**: æ¸¬é‡ **é€Ÿåº¦ï¼ˆVelocityï¼‰** å’Œ **å§¿æ…‹è®Šæ›ç‡ï¼ˆRate of Changeï¼‰**ã€‚
   - è·Œå€’ = $\frac{d(Head\_Position)}{dt}$ çªç„¶è®Šå¤§ + $Angle_{torso}$ è®Šç‚º 0ã€‚
   - å¦‚æœæ˜¯å¿«é€Ÿçš„å§¿æ…‹è®ŠåŒ–ï¼Œä½ ä¸éœ€è¦ç­‰å¾… 3 ç§’ä¾†ç¢ºèªï¼Œå¯ä»¥ç›´æ¥è§¸ç™¼ã€‚

### Phase 4: Accelerate (åŠ é€Ÿ)

1. **Python Version**: README å¯« Python 3.12ã€‚å°æ–¼åŸå‹ï¼ˆPrototypeï¼‰å¯ä»¥ã€‚ä½†è‹¥éƒ¨ç½²åˆ° Edge (Raspberry Pi/Jetson)ï¼Œæ­¤æ¶æ§‹ä¾ç„¶é©ç”¨ï¼Œä½†éœ€æ³¨æ„å„ªåŒ–ã€‚
2. **Docker**: å¾ˆå¥½ï¼Œä¿æŒé€™å€‹ã€‚é€™æ˜¯å”¯ä¸€èƒ½è®“éƒ¨ç½²æ¨™æº–åŒ–çš„æ±è¥¿ã€‚
3. **Delay Confirm (3s)**:
   - åœ¨æ€¥æ•‘å ´æ™¯ä¸­ï¼Œ3 ç§’æ˜¯æ°¸æ†ã€‚
   - å¦‚æœæ¨¡å‹æº–ç¢ºç‡å¤ é«˜ï¼ˆä½¿ç”¨éª¨æ¶è§’åº¦ï¼‰ï¼Œå¯ç¸®çŸ­è‡³ 0.5 ç§’æˆ– 0ã€‚
   - **æ­£ç¢ºé‚è¼¯**: "åµæ¸¬åˆ°é«˜è¡æ“ŠåŠ›å‹•ä½œ" $\rightarrow$ "ç™¼å‡ºè­¦å ±"ã€‚
   - **åŸå‰‡**: åœ¨å®‰å…¨é ˜åŸŸï¼ŒFalse Positive (èª¤å ±) å„ªæ–¼ False Negative (æ¼å ±)ã€‚

### Phase 5: Final Architecture (æœ€çµ‚æ¶æ§‹)

é€™æ˜¯æˆ‘æœƒæ§‹å»ºçš„ç‰ˆæœ¬ã€‚ç°¡å–®ï¼Œå¿«é€Ÿï¼Œæ²’æœ‰å»¢è©±ã€‚

1. **è¼¸å…¥ (Input)**: RTSP Stream / USB Cam
2. **è¨ˆç®—æ ¸å¿ƒ (Core Loop)**:
   - **Frame In**: å–å¾—å½±åƒã€‚
   - **Inference (TensorRT)**: é‹è¡Œ YOLOv8-Pose (è½‰ç‚º TensorRT æ ¼å¼åŠ é€Ÿ 5-10 å€)ã€‚
   - **Vector Analysis**: è¨ˆç®—è»€å¹¹å‘é‡ $V_{torso}$ èˆ‡åœ°é¢çš„å¤¾è§’ $\theta$ã€‚
   - **Trigger**: If $\theta < 20^\circ$ AND $\Delta t_{change} < 500ms$ $\rightarrow$ **FALL DETECTED**.
3. **Action**:
   - å¯«å…¥ SQLite (Metadata).
   - è§¸ç™¼ Webhook (Line Notify).
   - ä¿å­˜å‰å¾Œ 10s å½±ç‰‡ (Rolling Buffer Dump).

**åˆªé™¤çš„æ±è¥¿**ï¼š

- LLM (Useless).
- è¤‡é›œçš„ "Delay Confirm" ç‹€æ…‹æ©Ÿ (ç”¨ç‰©ç†ç‰¹å¾µå–ä»£äººç‚ºå»¶é²).
- åˆ†æ•£çš„å„²å­˜é‚è¼¯.

### Verdict

ç›®å‰çš„ç³»çµ±æ˜¯å…¸å‹çš„ã€Œå †ç–Šå¼é–‹ç™¼ã€ï¼ˆStack-based developmentï¼‰ã€‚èƒ½è·‘ï¼Œä½†è‡ƒè…«ã€‚å¦‚æœä½ æƒ³æŠŠå®ƒè®Šæˆç”¢å“ï¼Œ**Delete the LLM reference, optimize the physics logic, and ship it.**

## 3

æ ¹æ“šä½ çš„ç³»çµ±æ¶æ§‹ï¼ŒYOLO å·²ç¶“å¹«ä½ è§£æ±ºäº†æœ€é›£çš„ã€Œæ„ŸçŸ¥ã€å•é¡Œï¼ˆçµ¦å‡ºäº† Keypointsï¼‰ï¼Œä½ çš„ã€Œç‰©ç†å¼•æ“ã€åªéœ€è¦åšä¸€ä»¶äº‹ï¼š**åˆ¤æ–·é€™äº›é»çš„å¹¾ä½•é—œä¿‚è®ŠåŒ–æ˜¯å¦ç¬¦åˆé‡åŠ›åŠ é€Ÿåº¦å°è‡´çš„å¤±æ§ã€‚**

```python
import numpy as np
from dataclasses import dataclass

@dataclass
class PoseState:
    norm_torso_vector: np.array  # [dx, dy] normalized
    hip_velocity_y: float        # Normalized distance per second
    bbox_aspect_ratio: float     # width / height

class FallDetector:
    def __init__(self, fps=30):
        # Good Taste: Configurable, scale-invariant thresholds
        self.FALL_ASPECT_RATIO = 1.2  # Width > Height means lying down
        self.IMPACT_VELOCITY = 0.05   # 5% of screen height per frame (fast!)
        self.GRAVITY_VECTOR = np.array([0, 1]) # Assuming camera is upright

    def analyze(self, keypoints, history) -> bool:
        """
        Returns True if fall detected.
        Input: keypoints (normalized 0-1), history (previous frames)
        """
        # 1. Simplify Data Structure: Get Torso Vector
        # Index: 5=L_Shoulder, 6=R_Shoulder, 11=L_Hip, 12=R_Hip
        mid_shoulder = (keypoints[5] + keypoints[6]) / 2
        mid_hip = (keypoints[11] + keypoints[12]) / 2

        torso_vector = mid_shoulder - mid_hip

        # 2. The Math (Geometry): Alignment with Gravity
        # Dot product is faster and cleaner than calculating degrees.
        # If torso aligns with gravity, dot product is ~1. If horizontal, ~0.
        vertical_alignment = np.dot(torso_vector, self.GRAVITY_VECTOR)

        # 3. The Physics: Velocity (Kinetic Energy proxy)
        prev_hip = history[-1].mid_hip if history else mid_hip
        velocity_y = (mid_hip[1] - prev_hip[1]) # Positive means going down

        # 4. The Logic: Combine Spatial and Temporal features
        # A fall is: Not Vertical anymore AND (Moved down fast OR Is wide on ground)

        is_horizontal = abs(vertical_alignment) < 0.5 # Less than ~60 degrees projection
        high_impact = velocity_y > self.IMPACT_VELOCITY

        # Heuristic: If you are horizontal and logic suggests you hit the ground hard
        if is_horizontal and high_impact:
             return True

        # Catch the "Slow Fall" (Old people): Horizontal for N frames?
        # That belongs in the State Machine logic, not per-frame physics.

        return False
```
